{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "> ğŸŒŸ å¦‚æœä½ è§‰å¾— ChatTTS å’Œ ChatTTS_colab é¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·è®¿é—®ä»¥ä¸‹é“¾æ¥ç»™å®ƒä»¬ç‚¹ä¸ªæ˜Ÿæ˜Ÿå§ï¼ğŸŒŸ\n",
        "\n",
        "- [ChatTTS é¡¹ç›®](https://github.com/2noise/ChatTTS)\n",
        "\n",
        "- [ChatTTS_colab é¡¹ç›®](https://github.com/6drf21e/ChatTTS_colab)\n",
        "\n",
        "æ„Ÿè°¢ä½ çš„æ”¯æŒï¼\n",
        "\n",
        "# è¿è¡Œæ–¹æ³•\n",
        "\n",
        "- ç‚¹å‡»èœå•æ çš„--ä»£ç æ‰§è¡Œç¨‹åº--å…¨éƒ¨è¿è¡Œå³å¯\n",
        "- æ‰§è¡Œååœ¨ä¸‹æ–¹çš„æ—¥å¿—ä¸­æ‰¾åˆ°ç±»ä¼¼\n",
        "\n",
        "  Running on public URL: https://**************.gradio.live  <-è¿™ä¸ªå°±æ˜¯å¯ä»¥è®¿é—®çš„å…¬ç½‘åœ°å€\n",
        "\n",
        "å®‰è£…åŒ…çš„æ—¶å€™æç¤ºè¦é‡å¯ è¯·ç‚¹**\"å¦\"**"
      ],
      "metadata": {
        "id": "Xo3k5XsTzWK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. å®‰è£…ä¾èµ–å’Œå…‹éš†ä»“åº“\n",
        "!git clone https://github.com/6drf21e/ChatTTS_colab.git\n",
        "%cd ChatTTS_colab\n",
        "\n",
        "# 2. å®‰è£…å¿…è¦çš„åŒ…\n",
        "!pip install -r requirements-macos.txt\n",
        "!pip install pynini==2.1.5\n",
        "!pip install WeTextProcessing\n",
        "!pip install transformers==4.30.2 tokenizers --upgrade\n",
        "\n",
        "# 3. å…‹éš†å’Œè®¾ç½®ChatTTS\n",
        "!git clone https://github.com/2noise/ChatTTS.git\n",
        "%cd ChatTTS\n",
        "!git checkout e6412b1\n",
        "%cd ..\n",
        "\n",
        "# 4. ç§»åŠ¨æ–‡ä»¶åˆ°æ­£ç¡®ä½ç½®\n",
        "!mv ChatTTS temp\n",
        "!mv temp/ChatTTS ./ChatTTS\n",
        "!rm -rf temp\n",
        "\n",
        "# 5. åˆ›å»ºå¹¶è¿è¡Œä¿®å¤è„šæœ¬\n",
        "with open('fix_tokenizer.py', 'w') as f:\n",
        "    f.write('''\n",
        "import fileinput\n",
        "import sys\n",
        "\n",
        "filepath = \"ChatTTS/core.py\"\n",
        "with open(filepath, 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "if \"self.models['tokenizer'].pad_token = '[PAD]'\" not in content:\n",
        "    modified_content = content.replace(\n",
        "        \"self.models['tokenizer'] = AutoTokenizer.from_pretrained(\",\n",
        "        \"self.models['tokenizer'] = AutoTokenizer.from_pretrained(\\\\n        self.models['tokenizer'].pad_token = '[PAD]'\"\n",
        "    )\n",
        "\n",
        "    with open(filepath, 'w') as file:\n",
        "        file.write(modified_content)\n",
        "''')\n",
        "\n",
        "!python fix_tokenizer.py\n",
        "\n",
        "# 6. ä¿®æ”¹api.pyä¸­çš„paddingè®¾ç½®\n",
        "!sed -i 's/padding=True/padding=False/g' ChatTTS/infer/api.py || echo \"sed command failed, continuing anyway\"\n",
        "\n",
        "# 7. ä¿®å¤sentence-transformersä¾èµ–å†²çª\n",
        "!pip install -U sentence-transformers transformers>=4.41.0\n",
        "\n",
        "# 8. è¿è¡Œç¨‹åº\n",
        "!python webui_mix.py --share"
      ],
      "metadata": {
        "id": "hNDl-5muR77-",
        "outputId": "d1207005-0c1b-439b-900b-950a7bd5c27f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ChatTTS_colab'...\n",
            "remote: Enumerating objects: 217, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 217 (delta 26), reused 23 (delta 23), pack-reused 171 (from 2)\u001b[K\n",
            "Receiving objects: 100% (217/217), 2.01 MiB | 4.65 MiB/s, done.\n",
            "Resolving deltas: 100% (115/115), done.\n",
            "/content/ChatTTS_colab\n",
            "Collecting aiofiles (from -r requirements-macos.txt (line 1))\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: altair in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 2)) (5.5.0)\n",
            "Requirement already satisfied: annotated-types in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 3)) (0.7.0)\n",
            "Collecting antlr4-python3-runtime (from -r requirements-macos.txt (line 4))\n",
            "  Downloading antlr4_python3_runtime-4.13.2-py3-none-any.whl.metadata (304 bytes)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 5)) (3.7.1)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 6)) (24.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 7)) (2024.12.14)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 8)) (3.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 9)) (8.1.7)\n",
            "Collecting cn2an (from -r requirements-macos.txt (line 10))\n",
            "  Downloading cn2an-0.5.23-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: contourpy in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 11)) (1.3.1)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 12)) (0.12.1)\n",
            "Requirement already satisfied: distro in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 13)) (1.9.0)\n",
            "Collecting dnspython (from -r requirements-macos.txt (line 14))\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 15)) (0.8.0)\n",
            "Collecting einx (from -r requirements-macos.txt (line 16))\n",
            "  Downloading einx-0.3.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting email_validator (from -r requirements-macos.txt (line 17))\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting encodec (from -r requirements-macos.txt (line 18))\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fastapi (from -r requirements-macos.txt (line 19))\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting fastapi-cli (from -r requirements-macos.txt (line 20))\n",
            "  Downloading fastapi_cli-0.0.7-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting ffmpy (from -r requirements-macos.txt (line 21))\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 22)) (3.16.1)\n",
            "Requirement already satisfied: fonttools in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 23)) (4.55.3)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 24)) (2.4.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 25)) (2024.10.0)\n",
            "Collecting gradio (from -r requirements-macos.txt (line 26))\n",
            "  Downloading gradio-5.9.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting gradio_client (from -r requirements-macos.txt (line 27))\n",
            "  Downloading gradio_client-1.5.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: h11 in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 28)) (0.14.0)\n",
            "Requirement already satisfied: httpcore in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 29)) (1.0.7)\n",
            "Collecting httptools (from -r requirements-macos.txt (line 30))\n",
            "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 31)) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 32)) (0.27.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 33)) (3.10)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 34)) (6.4.5)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 35)) (0.42.1)\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 36)) (3.1.4)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 37)) (4.23.0)\n",
            "Requirement already satisfied: jsonschema-specifications in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 38)) (2024.10.1)\n",
            "Requirement already satisfied: kiwisolver in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 39)) (1.4.7)\n",
            "Requirement already satisfied: markdown-it-py in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 40)) (3.0.0)\n",
            "Requirement already satisfied: MarkupSafe in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 41)) (3.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 42)) (3.8.0)\n",
            "Requirement already satisfied: mdurl in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 43)) (0.1.2)\n",
            "Requirement already satisfied: mpmath in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 44)) (1.3.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 45)) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 46)) (1.26.4)\n",
            "Collecting omegaconf (from -r requirements-macos.txt (line 47))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 48)) (1.57.4)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 49)) (3.10.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 50)) (24.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 51)) (2.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 52)) (11.0.0)\n",
            "Collecting proces (from -r requirements-macos.txt (line 53))\n",
            "  Downloading proces-0.1.7-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 54)) (2.10.3)\n",
            "Requirement already satisfied: pydantic_core in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 55)) (2.27.1)\n",
            "Collecting pydub (from -r requirements-macos.txt (line 56))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: Pygments in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 57)) (2.18.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 58)) (3.2.0)\n",
            "Collecting pypinyin (from -r requirements-macos.txt (line 59))\n",
            "  Downloading pypinyin-0.53.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 60)) (2.8.2)\n",
            "Collecting python-dotenv (from -r requirements-macos.txt (line 61))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting python-multipart (from -r requirements-macos.txt (line 62))\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 63)) (2024.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 64)) (6.0.2)\n",
            "Requirement already satisfied: referencing in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 65)) (0.35.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 66)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 67)) (2.32.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 68)) (13.9.4)\n",
            "Requirement already satisfied: rpds-py in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 69)) (0.22.3)\n",
            "Collecting ruff (from -r requirements-macos.txt (line 70))\n",
            "  Downloading ruff-0.8.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 71)) (0.4.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 72)) (1.13.1)\n",
            "Collecting semantic-version (from -r requirements-macos.txt (line 73))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 74)) (1.5.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 75)) (1.17.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 76)) (1.3.1)\n",
            "Collecting socksio (from -r requirements-macos.txt (line 77))\n",
            "  Downloading socksio-1.0.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting starlette (from -r requirements-macos.txt (line 78))\n",
            "  Downloading starlette-0.43.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 79)) (1.13.1)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 80)) (0.21.0)\n",
            "Collecting tomlkit (from -r requirements-macos.txt (line 81))\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 82)) (0.12.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 83)) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 84)) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 85)) (4.67.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 86)) (4.47.1)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 87)) (0.15.1)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 88)) (4.12.2)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 89)) (2024.2)\n",
            "Collecting ujson (from -r requirements-macos.txt (line 90))\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 91)) (2.2.3)\n",
            "Collecting uvicorn (from -r requirements-macos.txt (line 92))\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting uvloop (from -r requirements-macos.txt (line 93))\n",
            "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting vector-quantize-pytorch (from -r requirements-macos.txt (line 94))\n",
            "  Downloading vector_quantize_pytorch-1.20.11-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting vocos (from -r requirements-macos.txt (line 95))\n",
            "  Downloading vocos-0.1.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting watchfiles (from -r requirements-macos.txt (line 96))\n",
            "  Downloading watchfiles-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from -r requirements-macos.txt (line 97)) (14.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.10/dist-packages (from altair->-r requirements-macos.txt (line 2)) (1.18.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->-r requirements-macos.txt (line 5)) (1.2.2)\n",
            "Collecting starlette (from -r requirements-macos.txt (line 78))\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting rich-toolkit>=0.11.1 (from fastapi-cli->-r requirements-macos.txt (line 20))\n",
            "  Downloading rich_toolkit-0.12.0-py3-none-any.whl.metadata (966 bytes)\n",
            "Collecting aiofiles (from -r requirements-macos.txt (line 1))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting MarkupSafe (from -r requirements-macos.txt (line 41))\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio->-r requirements-macos.txt (line 26))\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting antlr4-python3-runtime (from -r requirements-macos.txt (line 4))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai->-r requirements-macos.txt (line 48)) (0.8.2)\n",
            "Downloading cn2an-0.5.23-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m224.9/224.9 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einx-0.3.0-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi_cli-0.0.7-py3-none-any.whl (10 kB)\n",
            "Downloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading gradio-5.9.1-py3-none-any.whl (57.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.2/57.2 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.5.2-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m320.4/320.4 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading proces-0.1.7-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading pypinyin-0.53.0-py2.py3-none-any.whl (834 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m834.7/834.7 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.8.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading socksio-1.0.0-py3-none-any.whl (12 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading vector_quantize_pytorch-1.20.11-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading vocos-0.1.0-py3-none-any.whl (24 kB)\n",
            "Downloading watchfiles-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m443.8/443.8 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich_toolkit-0.12.0-py3-none-any.whl (13 kB)\n",
            "Downloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Building wheels for collected packages: encodec, antlr4-python3-runtime\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45760 sha256=fd1bdf4e4ef0f25136e0cd181c8dc25b3052577892a302eaa1363aadde703290\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/36/cb/81af8b985a5f5e0815312d5e52b41263237af07b977e6bcbf3\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=8daacea582854de53158d9d26c0ff1debad662c35e39ca45f05052141a711da7\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built encodec antlr4-python3-runtime\n",
            "Installing collected packages: pydub, antlr4-python3-runtime, uvloop, uvicorn, ujson, tomlkit, socksio, semantic-version, ruff, python-multipart, python-dotenv, pypinyin, proces, omegaconf, MarkupSafe, httptools, ffmpy, dnspython, aiofiles, watchfiles, starlette, email_validator, einx, cn2an, safehttpx, rich-toolkit, gradio_client, fastapi, vector-quantize-pytorch, gradio, fastapi-cli, encodec, vocos\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed MarkupSafe-2.1.5 aiofiles-23.2.1 antlr4-python3-runtime-4.9.3 cn2an-0.5.23 dnspython-2.7.0 einx-0.3.0 email_validator-2.2.0 encodec-0.1.1 fastapi-0.115.6 fastapi-cli-0.0.7 ffmpy-0.5.0 gradio-5.9.1 gradio_client-1.5.2 httptools-0.6.4 omegaconf-2.3.0 proces-0.1.7 pydub-0.25.1 pypinyin-0.53.0 python-dotenv-1.0.1 python-multipart-0.0.20 rich-toolkit-0.12.0 ruff-0.8.4 safehttpx-0.1.6 semantic-version-2.10.0 socksio-1.0.0 starlette-0.41.3 tomlkit-0.13.2 ujson-5.10.0 uvicorn-0.34.0 uvloop-0.21.0 vector-quantize-pytorch-1.20.11 vocos-0.1.0 watchfiles-1.0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "d6256ccd40124403a815e30a1bbf6e10"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pynini==2.1.5\n",
            "  Downloading pynini-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: Cython>=0.29 in /usr/local/lib/python3.10/dist-packages (from pynini==2.1.5) (3.0.11)\n",
            "Downloading pynini-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m161.3/161.3 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pynini\n",
            "Successfully installed pynini-2.1.5\n",
            "Collecting WeTextProcessing\n",
            "  Downloading WeTextProcessing-1.0.4.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting pynini==2.1.6 (from WeTextProcessing)\n",
            "  Downloading pynini-2.1.6-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from WeTextProcessing) (6.4.5)\n",
            "Downloading WeTextProcessing-1.0.4.1-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynini-2.1.6-cp310-cp310-manylinux_2_28_x86_64.whl (154.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.5/154.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pynini, WeTextProcessing\n",
            "  Attempting uninstall: pynini\n",
            "    Found existing installation: pynini 2.1.5\n",
            "    Uninstalling pynini-2.1.5:\n",
            "      Successfully uninstalled pynini-2.1.5\n",
            "Successfully installed WeTextProcessing-1.0.4.1 pynini-2.1.6\n",
            "Collecting transformers==4.30.2\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl.metadata (113 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m113.6/113.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (2.32.3)\n",
            "Collecting tokenizers\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.2) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.2) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.2) (2024.12.14)\n",
            "Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.0\n",
            "    Uninstalling tokenizers-0.21.0:\n",
            "      Successfully uninstalled tokenizers-0.21.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.47.1\n",
            "    Uninstalling transformers-4.47.1:\n",
            "      Successfully uninstalled transformers-4.47.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 3.3.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.30.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.13.3 transformers-4.30.2\n",
            "Cloning into 'ChatTTS'...\n",
            "remote: Enumerating objects: 2629, done.\u001b[K\n",
            "remote: Counting objects: 100% (737/737), done.\u001b[K\n",
            "remote: Compressing objects: 100% (297/297), done.\u001b[K\n",
            "remote: Total 2629 (delta 517), reused 440 (delta 440), pack-reused 1892 (from 2)\u001b[K\n",
            "Receiving objects: 100% (2629/2629), 7.99 MiB | 14.11 MiB/s, done.\n",
            "Resolving deltas: 100% (1582/1582), done.\n",
            "/content/ChatTTS_colab/ChatTTS\n",
            "Note: switching to 'e6412b1'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "HEAD is now at e6412b1 fix(ipy): missing envs (#379)\n",
            "/content/ChatTTS_colab\n",
            "2024-12-27 07:03:16.660184: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-27 07:03:16.690401: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-27 07:03:16.700681: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-27 07:03:16.726404: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-27 07:03:18.444589: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Loading ChatTTS model...\n",
            "INFO:ChatTTS.core:Download from HF: https://huggingface.co/2Noise/ChatTTS\n",
            "Fetching 12 files:   0% 0/12 [00:00<?, ?it/s]\n",
            "config/decoder.yaml: 100% 117/117 [00:00<00:00, 744kB/s]\n",
            "\n",
            "Decoder.pt:   0% 0.00/104M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Vocos.pt:   0% 0.00/54.4M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "DVAE_full.pt:   0% 0.00/60.4M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.pt:   0% 0.00/337k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "spk_stat.pt: 100% 4.26k/4.26k [00:00<00:00, 15.4MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "DVAE.pt:   0% 0.00/27.7M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.pt: 100% 337k/337k [00:00<00:00, 7.84MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "config/dvae.yaml: 100% 143/143 [00:00<00:00, 697kB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "config/gpt.yaml: 100% 346/346 [00:00<00:00, 2.08MB/s]\n",
            "\n",
            "Decoder.pt:  10% 10.5M/104M [00:00<00:02, 39.8MB/s]\u001b[A\n",
            "\n",
            "Vocos.pt:  19% 10.5M/54.4M [00:00<00:01, 40.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "DVAE_full.pt:  17% 10.5M/60.4M [00:00<00:01, 39.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "DVAE.pt:  38% 10.5M/27.7M [00:00<00:00, 38.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:   1% 10.5M/901M [00:00<00:23, 38.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "config/path.yaml: 100% 309/309 [00:00<00:00, 2.00MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "config/vocos.yaml: 100% 460/460 [00:00<00:00, 3.24MB/s]\n",
            "\n",
            "Decoder.pt:  20% 21.0M/104M [00:00<00:01, 41.6MB/s]\u001b[A\n",
            "\n",
            "Vocos.pt:  39% 21.0M/54.4M [00:00<00:00, 40.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "DVAE_full.pt:  35% 21.0M/60.4M [00:00<00:00, 40.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "DVAE.pt:  76% 21.0M/27.7M [00:00<00:00, 40.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:   2% 21.0M/901M [00:00<00:22, 39.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "DVAE.pt: 100% 27.7M/27.7M [00:00<00:00, 40.5MB/s]\n",
            "Fetching 12 files:   8% 1/12 [00:00<00:10,  1.05it/s]\n",
            "Decoder.pt:  30% 31.5M/104M [00:00<00:01, 42.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "DVAE_full.pt:  52% 31.5M/60.4M [00:00<00:00, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Vocos.pt:  58% 31.5M/54.4M [00:00<00:00, 41.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:   3% 31.5M/901M [00:00<00:20, 42.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Decoder.pt:  40% 41.9M/104M [00:00<00:01, 42.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "DVAE_full.pt:  69% 41.9M/60.4M [00:00<00:00, 43.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Vocos.pt:  77% 41.9M/54.4M [00:01<00:00, 41.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:   5% 41.9M/901M [00:01<00:20, 42.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Decoder.pt:  51% 52.4M/104M [00:01<00:01, 42.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "DVAE_full.pt:  87% 52.4M/60.4M [00:01<00:00, 42.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Vocos.pt:  96% 52.4M/54.4M [00:01<00:00, 42.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Vocos.pt: 100% 54.4M/54.4M [00:01<00:00, 41.9MB/s]\n",
            "\n",
            "\n",
            "\n",
            "DVAE_full.pt: 100% 60.4M/60.4M [00:01<00:00, 42.1MB/s]\n",
            "Fetching 12 files:  17% 2/12 [00:01<00:08,  1.21it/s]\n",
            "Decoder.pt:  61% 62.9M/104M [00:01<00:00, 42.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:   7% 62.9M/901M [00:01<00:19, 42.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Decoder.pt:  71% 73.4M/104M [00:01<00:00, 42.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:   8% 73.4M/901M [00:01<00:19, 42.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Decoder.pt:  81% 83.9M/104M [00:01<00:00, 42.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:   9% 83.9M/901M [00:02<00:19, 42.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Decoder.pt:  91% 94.4M/104M [00:02<00:00, 42.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  10% 94.4M/901M [00:02<00:19, 42.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Decoder.pt: 100% 104M/104M [00:02<00:00, 42.0MB/s]\n",
            "Fetching 12 files:  25% 3/12 [00:02<00:08,  1.11it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  12% 105M/901M [00:02<00:18, 42.7MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  13% 115M/901M [00:02<00:18, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  14% 126M/901M [00:02<00:18, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  15% 136M/901M [00:03<00:17, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  16% 147M/901M [00:03<00:17, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  17% 157M/901M [00:03<00:17, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  19% 168M/901M [00:03<00:17, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  20% 178M/901M [00:04<00:16, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  21% 189M/901M [00:04<00:16, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  22% 199M/901M [00:04<00:17, 41.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  23% 210M/901M [00:04<00:16, 41.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  24% 220M/901M [00:05<00:16, 41.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  26% 231M/901M [00:05<00:15, 42.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  27% 241M/901M [00:05<00:15, 42.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  28% 252M/901M [00:05<00:15, 42.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  29% 262M/901M [00:06<00:15, 42.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  30% 273M/901M [00:06<00:14, 42.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  31% 283M/901M [00:06<00:14, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  33% 294M/901M [00:06<00:14, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  34% 304M/901M [00:07<00:14, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  35% 315M/901M [00:07<00:13, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  36% 325M/901M [00:07<00:13, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  37% 336M/901M [00:07<00:13, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  38% 346M/901M [00:08<00:13, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  40% 357M/901M [00:08<00:12, 42.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  41% 367M/901M [00:08<00:12, 42.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  42% 377M/901M [00:08<00:12, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  43% 388M/901M [00:09<00:12, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  44% 398M/901M [00:09<00:11, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  45% 409M/901M [00:09<00:11, 42.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  47% 419M/901M [00:09<00:11, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  48% 430M/901M [00:10<00:11, 42.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  49% 440M/901M [00:10<00:11, 38.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  50% 451M/901M [00:10<00:11, 39.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  51% 461M/901M [00:11<00:11, 39.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  52% 472M/901M [00:11<00:10, 40.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  54% 482M/901M [00:11<00:10, 40.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  55% 493M/901M [00:11<00:09, 41.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  56% 503M/901M [00:11<00:09, 41.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  57% 514M/901M [00:12<00:09, 41.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  58% 524M/901M [00:12<00:08, 42.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  59% 535M/901M [00:12<00:08, 42.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  61% 545M/901M [00:12<00:08, 42.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  62% 556M/901M [00:13<00:08, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  63% 566M/901M [00:13<00:07, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  64% 577M/901M [00:13<00:07, 42.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  65% 587M/901M [00:13<00:07, 42.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  66% 598M/901M [00:14<00:07, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  68% 608M/901M [00:14<00:06, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  69% 619M/901M [00:14<00:06, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  70% 629M/901M [00:14<00:06, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  71% 640M/901M [00:15<00:06, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  72% 650M/901M [00:15<00:05, 42.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  73% 661M/901M [00:15<00:05, 42.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  75% 671M/901M [00:15<00:05, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  76% 682M/901M [00:16<00:05, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  77% 692M/901M [00:16<00:04, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  78% 703M/901M [00:16<00:04, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  79% 713M/901M [00:16<00:04, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  80% 724M/901M [00:17<00:04, 42.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  81% 734M/901M [00:17<00:04, 36.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  83% 744M/901M [00:17<00:04, 37.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  84% 755M/901M [00:18<00:03, 38.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  85% 765M/901M [00:18<00:03, 40.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  86% 776M/901M [00:18<00:03, 40.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  87% 786M/901M [00:18<00:02, 41.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  88% 797M/901M [00:19<00:02, 41.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  90% 807M/901M [00:19<00:02, 41.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  91% 818M/901M [00:19<00:01, 41.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  92% 828M/901M [00:19<00:01, 42.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  93% 839M/901M [00:20<00:01, 42.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  94% 849M/901M [00:20<00:01, 42.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  95% 860M/901M [00:20<00:00, 42.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  97% 870M/901M [00:20<00:00, 42.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  98% 881M/901M [00:21<00:00, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  99% 891M/901M [00:21<00:00, 42.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt: 100% 901M/901M [00:21<00:00, 41.9MB/s]\n",
            "Fetching 12 files: 100% 12/12 [00:21<00:00,  1.82s/it]\n",
            "INFO:ChatTTS.core:use cuda:0\n",
            "/content/ChatTTS_colab/ChatTTS/core.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  vocos.load_state_dict(torch.load(vocos_ckpt_path))\n",
            "INFO:ChatTTS.core:vocos loaded.\n",
            "/content/ChatTTS_colab/ChatTTS/core.py:115: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  dvae.load_state_dict(torch.load(dvae_ckpt_path))\n",
            "INFO:ChatTTS.core:dvae loaded.\n",
            "/content/ChatTTS_colab/ChatTTS/core.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  gpt.load_state_dict(torch.load(gpt_ckpt_path))\n",
            "/content/ChatTTS_colab/ChatTTS/core.py:132: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.pretrain_models['spk_stat'] = torch.load(spk_stat_path).to(device)\n",
            "INFO:ChatTTS.core:gpt loaded.\n",
            "/content/ChatTTS_colab/ChatTTS/core.py:139: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  decoder.load_state_dict(torch.load(decoder_ckpt_path, map_location='cpu'))\n",
            "INFO:ChatTTS.core:decoder loaded.\n",
            "/content/ChatTTS_colab/ChatTTS/core.py:144: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  tokenizer = torch.load(tokenizer_path, map_location='cpu')\n",
            "INFO:ChatTTS.core:tokenizer loaded.\n",
            "INFO:ChatTTS.core:All initialized.\n",
            "INFO:httpx:HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://api.gradio.app/v3/tunnel-request \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://cdn-media.huggingface.co/frpc-gradio-0.3/frpc_linux_amd64 \"HTTP/1.1 200 OK\"\n",
            "* Running on public URL: https://0da1dd0af081c48271.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        }
      ]
    }
  ]
}